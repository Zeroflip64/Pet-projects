{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wx3vvkMPD_lDvWqs8y5Bk_g3yTBK7xro",
      "authorship_tag": "ABX9TyPPXP4uNeqBuAL1qOax/z0e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zeroflip64/Pet-projects/blob/main/streamlit_1_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIRYwwi7ahxh",
        "outputId": "d406a89b-812f-40fd-e047-0c1ca61ff739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting streamlit\n",
            "  Downloading streamlit-1.22.0-py2.py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<5,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Collecting blinker>=1.0.0 (from streamlit)\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.3)\n",
            "Collecting importlib-metadata>=1.4 (from streamlit)\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.22.4)\n",
            "Requirement already satisfied: packaging>=14.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.1)\n",
            "Requirement already satisfied: pandas<3,>=0.25 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Collecting pympler>=0.9 (from streamlit)\n",
            "  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.8/164.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.27.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.3.4)\n",
            "Requirement already satisfied: tenacity<9,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.3)\n",
            "Collecting validators>=0.2 (from streamlit)\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gitpython!=3.1.19 (from streamlit)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck>=0.1.dev5 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.1)\n",
            "Collecting watchdog (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<5,>=3.2.0->streamlit) (0.12.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19->streamlit)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->streamlit) (3.15.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=0.25->streamlit) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->streamlit) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.4->streamlit) (3.4)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit) (2.14.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /usr/local/lib/python3.10/dist-packages (from tzlocal>=1.1->streamlit) (0.1.0.post0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from validators>=0.2->streamlit) (4.4.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<5,>=3.2.0->streamlit) (2.1.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.10/dist-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit) (2023.3)\n",
            "Building wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19579 sha256=4e6e221c54194bbfde57971187c2e17711d9a604e5ebf1fb22d981502456a8d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/ed/dd/d3a556ad245ef9dc570c6bcd2f22886d17b0b408dd3bbb9ac3\n",
            "Successfully built validators\n",
            "Installing collected packages: watchdog, validators, smmap, pympler, importlib-metadata, blinker, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed blinker-1.6.2 gitdb-4.0.10 gitpython-3.1.31 importlib-metadata-6.6.0 pydeck-0.8.1b0 pympler-1.0.1 smmap-5.0.0 streamlit-1.22.0 validators-0.20.0 watchdog-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P4axJWhbQko",
        "outputId": "c6742a6b-ab13-44d7-ffe0-035142194c6d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-6.0.0.tar.gz (681 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m681.2/681.2 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.0.0-py3-none-any.whl size=19867 sha256=982d11fd7815bf9bbf3719a5ebe5fcd510b7f60c0e67afc615c898aa91f9b772\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/42/78/0c3d438d7f5730451a25f7ac6cbf4391759d22a67576ed7c2c\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os"
      ],
      "metadata": {
        "id": "gGUahRntasOV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from mpl_toolkits.mplot3d import Axes3D #3d оси\n",
        "from yellowbrick.cluster import KElbowVisualizer#выбор кролчества кластеров\n",
        "from sklearn.cluster import KMeans,AgglomerativeClustering,DBSCAN\n",
        "from sklearn.preprocessing import OrdinalEncoder,StandardScaler,RobustScaler,MinMaxScaler\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import silhouette_score,calinski_harabasz_score,davies_bouldin_score\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import streamlit as st\n",
        "\n",
        "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "st.title(\"Project: Clustering of store customers to identify the best offers within the store chain.\")\n",
        "st.write('We have customer data of the grocery store chain.We will divide the project into several tasks:')\n",
        "\n",
        "\n",
        "st.text('Task 1: It is necessary to identify the model that will best be able to divide buyers.')\n",
        "st.text('Task 2: To analyze the resulting groups.')\n",
        "st.text('Task 3: Draw conclusions and make suggestions.')\n",
        "\n",
        "df=pd.read_csv('/content/drive/MyDrive/учеба/marketing_campaign.csv',sep='\\t')\n",
        "my_colors=['#730080','#00ab66','#636363','#779f73']\n",
        "\n",
        "\n",
        "\n",
        "st.title(\"DataFrame of this company\")\n",
        "st.table(df.head())\n",
        "\n",
        "st.write(\"Let's create a correlation matrix between the features to determine which features are important\")\n",
        "\n",
        "\n",
        "matrix_corr=df.corr()\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "go.Figure(data=go.Heatmap(z=matrix_corr))\n",
        "sns.heatmap(matrix_corr, annot=True, ax=ax)\n",
        "st.pyplot(fig)\n",
        "plt.close()  # Close the first graph\n",
        "\n",
        "st.write(\"Let's check the numerical signs for outliers and we use Z-score to determine outliers\")\n",
        "\n",
        "for i in [i for i in df.columns if df[i].dtype=='int']:\n",
        "  data=df[i]\n",
        "  z_scores = stats.zscore(data)\n",
        "  threshold = 3\n",
        "  outliers = df[np.abs(z_scores) > threshold]\n",
        "  df.loc[outliers.index, i] = None\n",
        "df.isna().sum().plot(kind='barh')\n",
        "st.pyplot()\n",
        "\n",
        "st.text('As we can see from the heat map and graph, we have columns that do not carry significance and abnormal data that we will delete')\n",
        "\n",
        "for i in ['NumWebPurchases', 'NumCatalogPurchases','NumWebVisitsMonth']:\n",
        "  df=df.loc[df[i]<15]\n",
        "df=df.drop(['Complain','AcceptedCmp2','Z_CostContact','Z_Revenue','AcceptedCmp3','NumDealsPurchases','Recency','ID','Dt_Customer','Response'],axis=1)\n",
        "df=df.loc[df['Income']<100000]#We also see values that are knocked out of the total mass in the amount of profit\n",
        "df=df.loc[df['Year_Birth']>1945]#We can see anomalies in the column with the date of birth, and therefore we will remove everyone older than 1945\n",
        "df=df.loc[df['NumWebPurchases']+df['NumCatalogPurchases']+df['NumStorePurchases']!=0]#Removed those customers who did not make purchases in stores\n",
        "df['Year_Birth']=df['Year_Birth'].astype('object')#Change of types \n",
        "columns_object=[i for i in  df.columns if df[i].dtypes!='int' and i!='Income' ]\n",
        "df=df.dropna()\n",
        "\n",
        "st.write('Creating new features')\n",
        "st.text(\"Let's combine the family statuses.\")\n",
        "st.text(\"Let's combine the signs of children and adolescents in the family.\")\n",
        "st.text(\"Let's identify the percentage of purchases made directly in the store.\")\n",
        "st.text(\"We will add new signs in the form of an average basket and customer activity.\")\n",
        "\n",
        "import numpy as np\n",
        "bad=['Absurd','Alone','YOLO']\n",
        "df=df.query('Marital_Status not in @bad')\n",
        "\n",
        "def maried_status(data):\n",
        "  \n",
        "  if data['Marital_Status']in ['Married','Together']:\n",
        "    return 'Married'\n",
        "  elif data['Marital_Status'] in ['Divorced','Widow']:\n",
        "    return 'Divorced'\n",
        "  else:\n",
        "    return data['Marital_Status']\n",
        "\n",
        "def offline(data):\n",
        "  online=data['NumWebPurchases']+data['NumCatalogPurchases']\n",
        "  offline=data['NumStorePurchases']\n",
        "  if online==0:\n",
        "    return 1\n",
        "  elif offline==0:\n",
        "    return 0\n",
        "  else:\n",
        "    return np.round(offline/(online+offline),2)\n",
        "\n",
        "df['Marital_Status']=df.apply(maried_status,axis=1)\n",
        "\n",
        "df['Childs']=df['Kidhome']+df['Teenhome']\n",
        "\n",
        "df['count_of_purchases']=df['NumWebPurchases']+df['NumCatalogPurchases']+df['NumStorePurchases']\n",
        "\n",
        "df['Basket']=np.round(df['Income']/(df['NumWebPurchases']+df['NumCatalogPurchases']+df['NumStorePurchases']),2)\n",
        "\n",
        "df['procent_offline']=df.apply(offline,axis=1)\n",
        "\n",
        "df['is_active']=((df['AcceptedCmp4']+df['AcceptedCmp5']+df['AcceptedCmp1'])>=2).map(int)\n",
        "\n",
        "df=df.drop(['Kidhome','Teenhome','AcceptedCmp4','AcceptedCmp5','AcceptedCmp1'],axis=1)\n",
        "\n",
        "st.write('Our datframe with new columns')\n",
        "st.table(df.head())\n",
        "\n",
        "st.write('')\n",
        "columns_num=[i for i in  df.columns if df[i].dtypes!='object' and i not in ['is_active','Response']]\n",
        "\n",
        "preprocesing=make_column_transformer((OrdinalEncoder(),['Education','Marital_Status']),\n",
        "                                     (StandardScaler(),columns_num),remainder='passthrough')\n",
        "important=df[[i for i in df.columns][:4]]\n",
        "\n",
        "\n",
        "df_encoder=pd.DataFrame(preprocesing.fit_transform(df),columns=df.columns)\n",
        "df_encoder.dropna(inplace=True)\n",
        "\n",
        "st.write('Due to the fact that we have quite a lot of features and there is also a correlation between them, we will use the PCA algorithm in order to reduce the dimension')\n",
        "\n",
        "pca=PCA(n_components=3)\n",
        "df_pca=pd.DataFrame(pca.fit_transform(df_encoder),columns=['list_c1','list_c2','list_c3'])\n",
        "\n",
        "st.write('Transformed data in space')\n",
        "\n",
        "x =df_pca[\"list_c1\"]\n",
        "y =df_pca[\"list_c2\"]\n",
        "z =df_pca[\"list_c3\"]\n",
        "fig = plt.figure(figsize=(14,10))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "ax.scatter(x,y,z, c=\"cyan\", marker=\"o\" )\n",
        "st.pyplot(fig)\n",
        "\n",
        "\n",
        "st.title('Task 1: It is necessary to identify the model that will best be able to divide buyers.')\n",
        "\n",
        "\n",
        "class claster:\n",
        "  def __init__(self,data):\n",
        "    self.data=data\n",
        "\n",
        "  def preprocesing(self,metod_of_object,metod_of_num):\n",
        "    columns_num=[i for i in  self.data.columns if self.data[i].dtypes!='object' and i not in ['is_active','Response']]\n",
        "\n",
        "    preprocesing=make_column_transformer((metod_of_object,['Education','Marital_Status']),\n",
        "                                     (metod_of_num,columns_num),remainder='passthrough')\n",
        "    \n",
        "    self.df_encoder=pd.DataFrame(preprocesing.fit_transform(self.data),columns=self.data.columns)\n",
        "    print('+')\n",
        "    pca=PCA(n_components=3)\n",
        "    self.df_pca=pd.DataFrame(pca.fit_transform(self.df_encoder),columns=['list_c1','list_c2','list_c3'])\n",
        "    return self.df_pca\n",
        "\n",
        "  def detected(self,algoritm,data):\n",
        "    self.algoritm=algoritm\n",
        "    Elbow_M = KElbowVisualizer(self.algoritm, k=10)\n",
        "    Elbow_M.fit(data)\n",
        "    Elbow_M.show()\n",
        "\n",
        "  def work(self,model,data,num,score):\n",
        "    models=model.fit(data)\n",
        "    data['labels']=models.labels_\n",
        "    silhouette_score=score[0](self.df_pca, models.labels_)\n",
        "    davies_bouldin_score=score[1](self.df_pca, models.labels_)\n",
        "    calinski_harabasz_score=score[2](self.df_pca, models.labels_)\n",
        "    \n",
        "    figer= go.Figure(data=[go.Scatter3d(x=data['list_c1'],y=data['list_c2'],\n",
        "    z=data['list_c3'],mode='markers',marker=dict(\n",
        "            size=4,\n",
        "            color=data['labels'], \n",
        "            opacity=0.8))])\n",
        "          \n",
        "    st.plotly_chart(figer)\n",
        "    plt.show()\n",
        "    st.write(pd.DataFrame({'Score':[silhouette_score,davies_bouldin_score,calinski_harabasz_score]},index=['silhouette_score','davies_bouldin_score','calinski_harabasz_score']))\n",
        "    return model.labels_\n",
        "    \n",
        "\n",
        "st.write('I decided to use two algorithms these are K means and Agglomerative (since these are algorithms of different principles, it will be interesting to see which of them will show the best indicator)')\n",
        "st.text('We use three metrics :')\n",
        "st.text('1) Silhouette score: The silhouette score measures how well each data point is separated from its own cluster compared to other clusters. It ranges from -1 to 1, with higher values indicating better cluster separation.')\n",
        "st.text('2) Calinski-Harabasz index: The Calinski-Harabasz index measures the ratio of the between-cluster variance to the within-cluster variance. Higher values indicate better cluster separation.')\n",
        "st.text('3) Davies-Bouldin index: The Davies-Bouldin index measures the average similarity between each cluster and its most similar cluster, and the average distance between each cluster and its least similar cluster. Lower values indicate better cluster separation.')\n",
        "\n",
        "st.write('The Best model')\n",
        "st.write('The best average of the three metrics was shown by the K means algorithm for 4 clusters in the future we will use it.')\n",
        "data=claster(df)\n",
        "kmeans=data.preprocesing(OrdinalEncoder(),MinMaxScaler())\n",
        "df['clusters']=data.work(KMeans(n_clusters=4),kmeans,4,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])\n",
        "\n",
        "st.title('If you want , you can experiment yourself')\n",
        "st.write(\"Let's choose different clustering models\")\n",
        "models = ['KMeans', 'Aglomeriv']\n",
        "selected_models = st.multiselect('Choose a model for clustering', models)\n",
        "\n",
        "if 'KMeans' in selected_models:\n",
        "  pre=['StandardScaler','RobustScaler','MinMaxScaler']\n",
        "  preproces=st.multiselect('Select a model for preprocessing features', pre)\n",
        "\n",
        "  if 'StandardScaler' in preproces:\n",
        "    data=claster(df)\n",
        "    kmeans=data.preprocesing(OrdinalEncoder(),StandardScaler())\n",
        "    num_of_clusters=st.number_input('select the number of clusters', min_value=2, max_value=12)\n",
        "    data.work(KMeans(n_clusters=num_of_clusters),kmeans,num_of_clusters,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])  \n",
        "    if st.button('Use it ?'): \n",
        "      df['clusters']=data.work(KMeans(n_clusters=num_of_clusters),kmeans,num_of_clusters,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])\n",
        "\n",
        "  if 'RobustScaler' in preproces:\n",
        "    data=claster(df)\n",
        "    kmeans=data.preprocesing(OrdinalEncoder(),RobustScaler())\n",
        "    num_of_clusters=st.number_input('select the number of clusters', min_value=2, max_value=12)\n",
        "    data.work(KMeans(n_clusters=num_of_clusters),kmeans,num_of_clusters,[silhouette_score,davies_bouldin_score,calinski_harabasz_score]) \n",
        "    if st.button('Use it ?'): \n",
        "      df['clusters']=data.work(KMeans(n_clusters=num_of_clusters),kmeans,num_of_clusters,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])\n",
        "\n",
        "  if 'MinMaxScaler' in preproces:\n",
        "    data=claster(df)\n",
        "    kmeans=data.preprocesing(OrdinalEncoder(),MinMaxScaler())\n",
        "    num_of_clusters=st.number_input('select the number of clusters', min_value=2, max_value=12)\n",
        "    data.work(KMeans(n_clusters=num_of_clusters),kmeans,num_of_clusters,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])\n",
        "    if st.button('Use it ?'): \n",
        "      df['clusters']=data.work(KMeans(n_clusters=num_of_clusters),kmeans,num_of_clusters,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])\n",
        "\n",
        "if 'Aglomeriv' in selected_models:\n",
        "  pre=['StandardScaler','RobustScaler','MinMaxScaler']\n",
        "  preproces=st.multiselect('Select a model for preprocessing features', pre)\n",
        "\n",
        "  if 'StandardScaler' in preproces:\n",
        "    data=claster(df)\n",
        "    aglo=data.preprocesing(OrdinalEncoder(),StandardScaler())\n",
        "    num_of_clusters=st.number_input('select the number of clusters', min_value=2, max_value=12)\n",
        "    st.text('Выебри метод :\"ward\",\"complete\",\"single\",\"average\"')\n",
        "    metod=st.text_input(' Method :')\n",
        "    data.work(AgglomerativeClustering(n_clusters=num_of_clusters, linkage=metod,compute_full_tree=True),aglo,2,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])\n",
        "    if st.button('Use it ?'):\n",
        "      df['clusters']=data.work(AgglomerativeClustering(n_clusters=num_of_clusters, linkage=metod,compute_full_tree=True),aglo,2,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])\n",
        "      \n",
        "  if 'RobustScaler' in preproces:\n",
        "    data=claster(df)\n",
        "    aglo=data.preprocesing(OrdinalEncoder(),RobustScaler())\n",
        "    num_of_clusters=st.number_input('select the number of clusters', min_value=2, max_value=12)\n",
        "    st.text('Выебри метод :\"ward\",\"complete\",\"single\",\"average\"')\n",
        "    metod=st.text_input(' Method :')\n",
        "    data.work(AgglomerativeClustering(n_clusters=num_of_clusters, linkage=metod,compute_full_tree=True),aglo,2,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])\n",
        "    if st.button('Use it ?'):\n",
        "      df['clusters']=data.work(AgglomerativeClustering(n_clusters=num_of_clusters, linkage=metod,compute_full_tree=True),aglo,2,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])\n",
        "\n",
        "  if 'MinMaxScaler' in preproces:\n",
        "    data=claster(df)\n",
        "    aglo=data.preprocesing(OrdinalEncoder(),MinMaxScaler())\n",
        "    num_of_clusters=st.number_input('select the number of clusters', min_value=2, max_value=12)\n",
        "    st.text('Выебри метод :ward,complete,single,average')\n",
        "    metod=st.text_input(' Method :')\n",
        "    data.work(AgglomerativeClustering(n_clusters=num_of_clusters, linkage=metod,compute_full_tree=True),aglo,2,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])\n",
        "    if st.button('Use it?'):\n",
        "      df['clusters']=data.work(AgglomerativeClustering(n_clusters=num_of_clusters, linkage=metod,compute_full_tree=True),aglo,2,[silhouette_score,davies_bouldin_score,calinski_harabasz_score])\n",
        "\n",
        "\n",
        "new_df=df\n",
        "new_df['clusters']=new_df['clusters'].astype('category')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "bar_columns=['Education','Marital_Status','Year_Birth']\n",
        "\n",
        "st.write('The ratio of the resulting clusters')\n",
        "st.table(new_df['clusters'].value_counts(normalize=True))\n",
        "\n",
        "def rename(data):\n",
        "  if data['clusters'] == 0:\n",
        "    return 'Group_1'\n",
        "  elif data['clusters']==1:\n",
        "    return 'Group_2'\n",
        "  elif data['clusters'] ==3:\n",
        "    return 'Group_3'\n",
        "  else:\n",
        "    return 'Group_4'\n",
        "\n",
        "new_df['clusters']=new_df.apply(rename,axis=1)\n",
        "\n",
        "st.title('Task 2: To analyze the resulting groups.')\n",
        "st.write(\"Let's divide our columns into several groups for analysis :\")\n",
        "st.text('A first group of nominative features that can provide general information about customers')\n",
        "st.text('A second group of attributes that display purchases of groups of certain products')\n",
        "st.text('A third group that will display the number of purchases where they are perfect and activity')\n",
        "\n",
        "first_category=['Year_Birth', 'Education', 'Marital_Status', 'Income','Basket','Childs']\n",
        "second_category=['MntWines','MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
        "                'MntSweetProducts','MntGoldProds']\n",
        "third_category=['NumWebVisitsMonth','NumWebPurchases', 'NumCatalogPurchases','NumStorePurchases',\n",
        "                'procent_offline','count_of_purchases']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "st.title('First group')\n",
        "\n",
        "for i in first_category:\n",
        "  if i not in ['Income','Basket','Year_Birth']:\n",
        "    plt.figure(figsize=(8,8))\n",
        "    data=new_df.pivot_table(index=i,columns='clusters',values='MntSweetProducts',aggfunc='count')\n",
        "    pivot_df = data.reset_index()\n",
        "    melted_df = pivot_df.melt(id_vars=i, value_name='count', var_name='clusters')\n",
        "    sns.barplot(x=i, y='count', hue='clusters', data=melted_df, palette=my_colors)\n",
        "    st.pyplot()\n",
        "    plt.show()\n",
        "  elif i=='Basket':\n",
        "    plt.figure(figsize=(8,8))\n",
        "    sns.kdeplot(data=new_df,x=new_df.loc[new_df[i]<10000][i],palette=my_colors,hue='clusters')\n",
        "    plt.axvline(new_df['Basket'].median(), linestyle='--', color='red')\n",
        "    plt.text(new_df['Basket'].median(),0,'Медиана корзины')\n",
        "    plt.show()\n",
        "    plt.figure(figsize=(8,8))\n",
        "    sns.jointplot(x=new_df[i],y=new_df['Income'],hue=new_df['clusters'],kind='kde',palette=my_colors,alpha=0.6)\n",
        "    st.pyplot()\n",
        "    plt.show()\n",
        "  elif i=='Year_Birth':\n",
        "    plt.figure(figsize=(8,8))\n",
        "    sns.kdeplot(data=new_df,x=new_df[i],palette=my_colors,hue='clusters',common_norm=False)\n",
        "    st.pyplot()\n",
        "  else:\n",
        "    plt.figure(figsize=(8,8))\n",
        "    sns.kdeplot(data=new_df,x=new_df[i],palette=my_colors,hue='clusters')\n",
        "    st.pyplot()\n",
        "    plt.show()\n",
        "\n",
        "st.write(\"\"\"Conclusion about first part\"\"\")\n",
        "st.subheader(\"Age:\")\n",
        "st.write(\"- Group 1 is the oldest of their age before 1961\")\n",
        "st.write(\"- Group 2 comes after from 1958 to 1972\")\n",
        "st.write(\"- Group 3 goes from 1978 to 1982\")\n",
        "st.write(\"- The last 4 groups are from 1988 to 2000\")\n",
        "st.write(\"\")\n",
        "  # Education\n",
        "st.subheader(\"Education:\")\n",
        "st.write(\"- The most educated is Group 2, followed by Group 3\")\n",
        "st.write(\"- The less educated group is the 4th group\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Marital status\n",
        "st.subheader(\"Marital status:\")\n",
        "st.write(\"- Most of all married in the first group and in 3\")\n",
        "st.write(\"- The least divorced in the 4th group may well be related to age\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Profit\n",
        "st.subheader(\"The profit that the groups bring:\")\n",
        "st.write(\"- Group 1 brings the least about 39 thousand\")\n",
        "st.write(\"- Group 2 on average brings from 45 thousand to 75 thousand\")\n",
        "st.write(\"- Group 3 on average brings 60 thousand and this is the best result since most of the people are focused here\")\n",
        "st.write(\"- As for Group 4, there is a clear division by part of this group on average bring about 30 thousand, and the other from 75 thousand to 80 thousand. This is considered the highest indicator, but the number of people here is not as large as the third group.\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Average basket\n",
        "st.subheader(\"The average basket:\")\n",
        "st.write(\"- The first group, we see that a large accumulation of about 3000 thousand and interestingly, with a small average basket, they generally bring about 70 thousand\")\n",
        "st.write(\"- Group 2 we see two points of accumulation, the first average basket is slightly above 6000 thousand, but they bring about 30 thousand total income, but at the same time the second point which has an average basket of 4500, but they bring much more from 55 to 75 thousand\")\n",
        "st.write(\"- As with the incomes of Group 3, the average basket is focused on 3 thousand with a total income of about 60 thousand\")\n",
        "st.write(\"- The last 4 group has as many as three points of accumulation, 1 point and 2 point is the average basket of 3 thousand and 6 thousand with an average income of no more than 30 thousand and 3 point is also 3 thousand of the average basket, but at the same time they bring about 70 thousand.\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Children\n",
        "st.subheader(\"Children:\")\n",
        "st.write(\"- We see that the 4 groups most often do not have children, and they have no more than 2 as much as possible\")\n",
        "st.write(\"- People from the second group have one child more often than others\")\n",
        "st.write(\"- People from groups 1 and 3 are the most large\")\n",
        "\n",
        "st.title('Second group')\n",
        "for i in second_category:\n",
        "  \n",
        "  sns.jointplot(x=new_df[i],y=new_df['Income'],hue=new_df['clusters'],kind='kde',palette=my_colors,alpha=0.6)\n",
        "  st.pyplot()\n",
        "\n",
        "st.write('')\n",
        "# Alcohol sales\n",
        "st.subheader(\"Alcohol sales:\")\n",
        "st.write(\"- Group 1 is ready to spend more than all other groups\")\n",
        "st.write(\"- Group 2 goes after it\")\n",
        "st.write(\"- The least buys alcohol 4 group\")\n",
        "st.write(\"- Then comes the third group\")\n",
        "st.write(\"\")\n",
        "st.write(\"We also see that, in general, the trend is that the more alcohol is bought, the more profit is made, but the main group of people is from 0 to 250 units.\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Fruit sales\n",
        "st.subheader(\"Fruit sales:\")\n",
        "st.write(\"- People from the 4th group buy fruit the most and at the same time bring the most profit\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Meat sales\n",
        "st.subheader(\"Meat sales:\")\n",
        "st.write(\"- The main sales for all groups are approximately in the same range from 0 to 250 units\")\n",
        "st.write(\"- The first group is actively allocated here, which has purchases in large quantities, there are purchases of 600 and 800 units\")\n",
        "st.write(\"- Rarely the 2nd group buys meat more than normal\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Fish sales\n",
        "st.subheader(\"Fish sales:\")\n",
        "st.write(\"- The trend keeps from 0 to 50 units in almost all groups\")\n",
        "st.write(\"- 4 groups have people who buy more than 100 units of fish\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Sweet goods sales\n",
        "st.subheader(\"Sweet goods sales:\")\n",
        "st.write(\"- Everyone buys in about the same range\")\n",
        "st.write(\"- 2 and 1 groups buy in larger quantities than the rest\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Promotional products sales\n",
        "st.subheader(\"Promotional products sales:\")\n",
        "st.write(\"- Promotional products are more popular with the 2nd group with a profit of up to 60 thousand, and the first group of people\")\n",
        "st.write(\"- The 4 groups that buy up to 50 units bring the company the most money\")\n",
        "\n",
        "st.title('Third group')\n",
        "for i in third_category:\n",
        "  if i not in ['procent_offline','count_of_purchases']:\n",
        "    plt.figure(figsize=(10,7))\n",
        "    sns.barplot(x=new_df[i],y=new_df['Income'],hue=new_df['clusters'], palette=my_colors)\n",
        "    st.pyplot()\n",
        "  else:\n",
        "    plt.figure(figsize=(10,7))\n",
        "    sns.jointplot(x=new_df[i],y=new_df['Income'],hue=new_df['clusters'],kind='kde',palette=my_colors,alpha=0.6)\n",
        "    st.pyplot()\n",
        "\n",
        "st.subheader(\"Site visit:\")\n",
        "st.write(\"- We see that the 1st and 4th group visited the site at least once\")\n",
        "st.write(\"- People of the 2nd and 3rd groups can do without visiting the site\")\n",
        "st.write(\"- The 3rd group most often visits the site 10 times\")\n",
        "st.write(\"- Group 4 makes the most purchases on the site\")\n",
        "st.write(\"- People who make purchases on the site bring the company no more than 65 thousand\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Catalog usage\n",
        "st.subheader(\"Catalog usage:\")\n",
        "st.write(\"- The catalog is more popular with the first group\")\n",
        "st.write(\"- People from the 4th group did not make more than 10 purchases on the catalog\")\n",
        "st.write(\"- More affluent people use the catalog\")\n",
        "st.write(\"- As from 3 to 10 purchases, the profit grows from 50 thousand to 80\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Purchases in a physical store\n",
        "st.subheader(\"Purchases in a physical store:\")\n",
        "st.write(\"- Group 4 makes purchases more often\")\n",
        "st.write(\"- But at the same time, they do not bring a lot of money\")\n",
        "st.write(\"- A small part of people from Group 2 did not make purchases in a physical store\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Offline buyers\n",
        "st.subheader(\"Offline buyers:\")\n",
        "st.write(\"- Some people from the 2nd and 3rd groups have never used online platforms when shopping\")\n",
        "st.write(\"- But at the same time, these categories do not bring much money\")\n",
        "st.write(\"- In the 1st group, we see that they make purchases less often in a physical store, but at the same time the profit they make is about 60 thousand\")\n",
        "st.write(\"- Group 4 can also be divided into two groups, those who use online more often and they spend more money, and those who are less likely to bring about 30 thousand on average\")\n",
        "\n",
        "\n",
        "color_map={'Group_1': 'red', 'Group_2': 'blue', 'Group_3': 'green','Group_4':'yellow'}\n",
        "\n",
        "st.title('Conduct your own research')\n",
        "\n",
        "if st.checkbox('scatter'):\n",
        "      columns_1=new_df.columns\n",
        "      selected_column_1 = st.selectbox('Select a column for the axis X ', columns_1)\n",
        "      columns_2=new_df.columns\n",
        "      selected_column_2 = st.selectbox('Select a column for the axis Y', columns_2)\n",
        "      fig=px.scatter(new_df, y=selected_column_2,x=selected_column_1, marginal_x='histogram', marginal_y='histogram',color='clusters',color_discrete_map=color_map)\n",
        "      \n",
        "      st.plotly_chart(fig)\n",
        "\n",
        "if st.checkbox('histogram'):\n",
        "      columns_x=new_df.columns\n",
        "      selected_column_x = st.selectbox('Select a column for the axis X ', columns_x)\n",
        "      fige = px.histogram(new_df, x=selected_column_x, nbins=100, opacity=0.7,color='clusters',color_discrete_map=color_map)\n",
        "      fige.update_layout(xaxis_rangeslider_visible=True)\n",
        "      st.plotly_chart(fige) \n",
        "\n",
        "st.title('Task 3: Draw conclusions and make suggestions.') \n",
        "\n",
        "st.subheader(\"Group 1:\")\n",
        "st.write(\"- Older demographic\")\n",
        "st.write(\"- Mostly married\")\n",
        "st.write(\"- Low profit generation\")\n",
        "st.write(\"- High average basket value\")\n",
        "st.write(\"- Prefers purchasing alcohol\")\n",
        "st.write(\"- Less likely to use online platforms\")\n",
        "st.write(\"\")\n",
        "st.write(\"Recomended:\")\n",
        "st.write(\"- Implement targeted promotions for alcohol, such as discounts, combo offers, or loyalty programs.\")\n",
        "st.write(\"- Provide in-store events or experiences that appeal to their age group and preferences.\")\n",
        "st.write(\"- Use traditional marketing channels like print ads, radio, or direct mail to reach them.\")\n",
        "st.write(\"- Offer a senior discount program or age-specific loyalty program that rewards them for repeat purchases.\")\n",
        "st.write(\"- Keep them informed of new alcohol products or limited-time offers through direct mail or print newsletters.\")\n",
        "st.write(\"- Provide exceptional in-store customer service and assistance, catering to their preferences and needs.\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Group 2\n",
        "st.subheader(\"Group 2:\")\n",
        "st.write(\"- Middle-aged demographic\")\n",
        "st.write(\"- Highly educated\")\n",
        "st.write(\"- Moderate profit generation\")\n",
        "st.write(\"- Varying average basket value\")\n",
        "st.write(\"- Prefers purchasing alcohol and promotional products\")\n",
        "st.write(\"- More likely to use online platforms\")\n",
        "st.write(\"\")\n",
        "st.write(\"Recomended:\")\n",
        "st.write(\"- Offer special deals on alcohol and promotional products, targeting their preferences.\")\n",
        "st.write(\"- Leverage their education by sharing informative content about products and their benefits.\")\n",
        "st.write(\"- Use a mix of traditional and digital marketing channels to reach this audience.\")\n",
        "st.write(\"- Share informative content related to their product preferences.\")\n",
        "st.write(\"- Use a mix of traditional and digital communication channels to maintain engagement.\")\n",
        "st.write(\"- Offer exclusive deals and promotions tailored to their preferences and education level.\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Group 3\n",
        "st.subheader(\"Group 3:\")\n",
        "st.write(\"- Middle-aged demographic\")\n",
        "st.write(\"- Married\")\n",
        "st.write(\"- High profit generation\")\n",
        "st.write(\"- Low average basket value\")\n",
        "st.write(\"- Similar preferences to Group 1\")\n",
        "st.write(\"\")\n",
        "st.write(\"Recomended:\")\n",
        "st.write(\"- Implement family-oriented promotions, considering their marital status and higher spending power.\")\n",
        "st.write(\"- Offer bundle deals or discounts to encourage increased spending per transaction.\")\n",
        "st.write(\"- Use both digital and traditional marketing channels to engage with them effectively.\")\n",
        "st.write(\"- Send personalized offers and promotions based on their purchase history and preferences.\")\n",
        "st.write(\"- Use family-oriented events or in-store experiences to keep them engaged and interested in your brand.\")\n",
        "st.write(\"- Leverage both digital and traditional marketing channels to maintain contact and encourage repeat purchases.\")\n",
        "st.write(\"\")\n",
        "\n",
        "# Group 4\n",
        "st.subheader(\"Group 4:\")\n",
        "st.write(\"- Younger demographic\")\n",
        "st.write(\"- Less educated\")\n",
        "st.write(\"- High profit generation with potential\")\n",
        "st.write(\"- Prefers purchasing fruits\")\n",
        "st.write(\"- Highly engaged with online store and catalog\")\n",
        "st.write(\"\")\n",
        "st.write(\"Recomended:\")\n",
        "st.write(\"- Encourage fruit purchases by offering discounts, bundles, or seasonal promotions.\")\n",
        "st.write(\"- Invest in improving the online shopping experience and promote exclusive online deals.\")\n",
        "st.write(\"- Utilize digital marketing channels, such as social media, email marketing, and influencer partnerships.\")\n",
        "st.write(\"- Implement a digital loyalty program that rewards them for repeat online purchases and catalog usage.\")\n",
        "st.write(\"- Use email marketing and social media to share exclusive online deals, seasonal fruit promotions, and relevant content.\")\n",
        "st.write(\"- Offer personalized product recommendations and a seamless online shopping experience to keep them engaged and loyal to your brand.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYPTBYCja_Uf",
        "outputId": "0fa8c978-b30b-4c64-e807-e13ed4d3c4fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "port = 8502\n",
        "\n",
        "\n",
        "ngrok.set_auth_token(\"2OPd0SjgLnOyuQaMw271tkOgGJX_6NbBsSBfgZRtwsqDpd5Ri\")\n",
        "public_url = ngrok.connect(port, \"http\", bind_tls=True)\n",
        "print(f\"Your Streamlit app is accessible at {public_url}\")\n",
        "\n",
        "\n",
        "!streamlit run app.py --server.port {port}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ex2RxMVWbAzQ",
        "outputId": "cbd4ad38-6938-42d7-8b0a-0bbe680074a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-05-16T07:44:59+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your Streamlit app is accessible at NgrokTunnel: \"https://cc49-35-237-150-63.ngrok-free.app\" -> \"http://localhost:8502\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to False.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8502\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.150.63:8502\u001b[0m\n",
            "\u001b[0m\n",
            "/content/app.py:39: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  matrix_corr=df.corr()\n",
            "+\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "/content/app.py:430: RuntimeWarning:\n",
            "\n",
            "More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}